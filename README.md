# Classification supervis√©e de textes et donn√©es m√©dicales  
Projet r√©alis√© dans le cadre du Master 1 Langue & Informatique √† Sorbonne Universit√©. L'objectif est de comparer plusieurs mod√®les de classification supervis√©e sur un corpus textuel.
**Auteures : Souka√Øna Bouhaid & Amina-M‚Äôbariqui Ahamada**

---

## üéØ Objectifs
Ce projet vise √† comparer plusieurs algorithmes de **classification supervis√©e** sur deux jeux de donn√©es diff√©rents :

1. **Student Health** (donn√©es m√©dicales et physiologiques)
2. **Short Text Humor Detection** (textes courts annot√©s selon leur caract√®re humoristique)

L‚Äôobjectif est :
- de tester plusieurs classifieurs,
- d‚Äô√©valuer leurs performances,
- d‚Äôoptimiser les r√©sultats (temps d‚Äôex√©cution et accuracy),
- d‚Äôidentifier les mod√®les les plus adapt√©s √† chaque probl√©matique.

---

## üìÇ Jeux de donn√©es

### 1) **Student Health Dataset**
Source : Kaggle  
Variables : donn√©es physiologiques, donn√©es cat√©gorielles (mood, sleep, etc.)  
Variable cible : **Stress_Level_Biosensor** (discr√©tis√©e en *faible / moyen / √©lev√©*)

Points cl√©s :
- encodage OneHotEncoder pour variables cat√©gorielles  
- transformation de la variable cible avec 'pandas.cut'  
- dataset d√©s√©quilibr√© ‚Üí attention aux m√©triques  

---

### 2) **Short Text Humor Detection**
Source : Kaggle  
200 000 textes courts annot√©s (humor = True/False)

Points cl√©s :
- vectorisation CountVectorizer puis TfidfVectorizer  
- r√©duction du temps d‚Äôex√©cution du mod√®le SVM  
- tests sur n-grammes, stopwords, max_features  

---

## üß† Algorithmes test√©s
Les mod√®les suivants ont √©t√© compar√©s :

- Perceptron  
- Logistic Regression  
- Random Forest  
- Support Vector Machine (SVM)

---

## ‚öôÔ∏è M√©thodologie g√©n√©rale
1. Analyse exploratoire  
2. Nettoyage & pr√©traitement  
3. Vectorisation (OneHotEncoder, CountVectorizer, TF-IDF)  
4. S√©paration train/test (70% / 30%)  
5. Entra√Ænement & comparaison des classifieurs  
6. Analyse des erreurs  
7. Optimisation (s√©lection de features, changement de vectoriseur)

---

## üèÜ Principaux r√©sultats

### **Student Health**
- SVM est le meilleur classifieur (accuracy ‚âà 0.60)
- Mod√®les lin√©aires tr√®s rapides mais moins efficaces
- Importance forte des variables :
  - Health_Risk_Level_Low
  - Health_Risk_Level_High

### **Humor Detection**
- Sans pr√©traitement : accuracy ‚âà 0.91 mais SVM tr√®s lent  
- Avec CountVectorizer : temps r√©duit, accuracy 0.93  
- Avec TF-IDF : execution ~316 sec, accuracy ‚âà 0.82

Conclusion :
- TF-IDF r√©duit fortement le temps
- CountVectorizer + SVM = meilleur compromis performance / vitesse
